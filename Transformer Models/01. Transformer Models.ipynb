{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr1Zs_mpYPSG"
   },
   "source": [
    "## **Natural Language Processing**\n",
    "\n",
    "- NLP is a field of linguistics and machine learning focused on understanding everything related to human lanauge. The aim of NLP task is not only to understand single words individually, but to be able to understand the context of those words.\n",
    "\n",
    "*Common NLP Tasks*\n",
    "\n",
    "- Classifying whole sentences\n",
    "- Classifying each word in sentence\n",
    "- Generating text context\n",
    "- Extracting an answer from a text\n",
    "- Generating a new sentence from an input text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFRl6gzRY4_A"
   },
   "source": [
    "**Why it is challenging**\n",
    "\n",
    "- Computers don’t process information in the same way as humans. For example, when we read the sentence “I am hungry,” we can easily understand its meaning. Similarly, given two sentences such as “I am hungry” and “I am sad,” we’re able to easily determine how similar they are. For machine learning (ML) models, such tasks are more difficult. The text needs to be processed in a way that enables the model to learn from it. And because language is complex, we need to think carefully about how this processing must be done. There has been a lot of research done on how to represent text, and we will look at some methods in the next chapter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buwaQCaNZf9J"
   },
   "source": [
    "## The Pipeline Function\n",
    "\n",
    "- The pipeline function is the most high-level API of the Transformers library\n",
    "\n",
    "- `Pipeline()` returns an end-to-end object that performs an NLP task on one or several texts\n",
    "\n",
    "- It regroups together all the steps to go from raw texts to usable predictions. The model used is at the core of pipeline, but the pipeline also include all the necessary pre-processing as well as some post-preprocessing to make the output of the model human-readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vt7lCI3cpSm"
   },
   "source": [
    "There are three main steps involved when we pass some text in pipeline:\n",
    "\n",
    "- Preprocessing a text in the format that model can understand\n",
    "- The preprocessed inputs are passed to the model\n",
    "- The predictions of the model are post-processed, so we can make sense of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6R885_CfaMUp"
   },
   "outputs": [],
   "source": [
    "#@ DOWNLOADING THE TRANSFORMERS LIBRARY\n",
    "\n",
    "# !pip --q install transformers\n",
    "# !pip --q install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp2lNJnIhh6u"
   },
   "source": [
    "**1. Sentiment Analysis**\n",
    "\n",
    "- It is a branch of natural language processing, which involves the emotional tone or sentiment expressed in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qtIzAvUzjWaM"
   },
   "outputs": [],
   "source": [
    "#@ LOADING THE REQUIRED LIBRARIES AND DEPENDENCIES\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGQtkkR5T9XB",
    "outputId": "45c22fe1-0de8-4317-f7c0-6c6af353607a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9516069889068604}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ SENTIMENT ANALYSIS PIPELINE\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hUa4CyMarR_",
    "outputId": "576b0c6d-5838-405d-8a7f-f61d847023d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998674392700195},\n",
       " {'label': 'NEGATIVE', 'score': 0.9992349147796631}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ Passing the multiple text to the pipeline\n",
    "classifier([\n",
    "    'This hugging face course is very good',\n",
    "    'I hate this soo much'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UED153IndA9q"
   },
   "source": [
    "**2. Zero - shot classification**\n",
    "\n",
    "- It is a machine learning technique that is used to classify the input data into multiple categories or classes, even if the model has not been explicitly trained on those categories during training phase.\n",
    "\n",
    "- It allows the model to make predictions about classes it has never seen before.\n",
    "\n",
    "- It majorly relies on the idea that langauge and semantic understanding can help bridge the gap between known and unknown classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmXQnzOXbFYi",
    "outputId": "f9967fa8-3475-4bc6-f3d2-49ba84c81f72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "#@ ZERO SHOT CLASSIFICATION PIPELINE\n",
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWciFRs3boCK",
    "outputId": "e495f7a8-09ad-4624-d063-e96c8ff29f66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about Transformer library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9460309743881226, 0.03919023275375366, 0.014778840355575085]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"This is a course about Transformer library\",\n",
    "    candidate_labels = [\"education\", \"business\", \"politics\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37zU8De_d_w0"
   },
   "source": [
    "**3. Text Generation**\n",
    "\n",
    "- The main idea of text generation is that when we provide prompt and the model will auto complete it by generating the remaining text.\n",
    "\n",
    "- It is similar to the predictive text feature that is found on many phones.\n",
    "\n",
    "- We can give several arguments like `num_return_sequences` and `max_length` to generate any sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yYIjtSAGb0QV"
   },
   "outputs": [],
   "source": [
    "#@ TEXT GENERATION PIPELINE\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYs8DYZzcREG",
    "outputId": "4efcfb32-740c-4e76-9c9b-4ef31faff42a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to use Hugging Face ID to learn how to use facial recognition.\\n\\n\\n\\n\\n\\nThe goal of this course is to learn how to use'},\n",
       " {'generated_text': 'In this course, we will teach you how to use Hugging Face Recognition.\\n\\n\\n\\nYou will probably have heard of this course from a bunch of others, especially, because they were'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"In this course, we will teach you how to use Hugging Face\",\n",
    "          max_length=40,\n",
    "          num_return_sequences=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmlT_3_Tepsr"
   },
   "source": [
    "**4. Mask Filling**\n",
    "\n",
    "- The idea of mask filling is to fill the blanks in a given text\n",
    "\n",
    "- The argument `top_k` is to control how many possibilities that we want to display. The model fills in the special `<mask>` word, which is often referred as *mask token*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbqAlGgfccbp",
    "outputId": "699c3aec-1a7c-45c5-c598-f12b072bd6df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#@ FILL MASK\n",
    "unmasker = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqfr-6SqgYyW",
    "outputId": "9e030985-e219-4b20-b9de-98716ac09152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4101862907409668,\n",
       "  'token': 2239,\n",
       "  'token_str': ' learning',\n",
       "  'sequence': 'You will be implementing deep learning models.'},\n",
       " {'score': 0.09801976382732391,\n",
       "  'token': 26739,\n",
       "  'token_str': ' neural',\n",
       "  'sequence': 'You will be implementing deep neural models.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"You will be implementing deep <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abeM86iHhiag"
   },
   "source": [
    "**5. Named Entity Recognition**  \n",
    "\n",
    "NER pipeline identifies entities such as persons, organizations or locations in a sentence.\n",
    "\n",
    "- When we pass `grouped_entities=True` in the pipeline creation function to tell the pipeline to regroup together the parts of the sentences that correspond to the same entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8wyRIHXgfNY",
    "outputId": "773792a9-3f53-4fc1-fb74-a9370a7185a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99854356,\n",
       "  'word': 'Saugat Regmi',\n",
       "  'start': 11,\n",
       "  'end': 23},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9829941,\n",
       "  'word': 'Mercantile',\n",
       "  'start': 38,\n",
       "  'end': 48},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9983037,\n",
       "  'word': 'Kathmandu',\n",
       "  'start': 52,\n",
       "  'end': 61}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ NAMED ENTITY RECOGNITION\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Saugat Regmi and I work at Mercantile in Kathmandu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByZJkOaPfY7Y"
   },
   "source": [
    "**6. Question Answering**\n",
    "\n",
    "- This pipeline helps answering the questions using information given from the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqBU4yyUhFx9",
    "outputId": "ead91805-b89f-42a6-cf90-47718b735322"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8813986778259277,\n",
       " 'start': 38,\n",
       " 'end': 52,\n",
       " 'answer': 'Mercantile Inc'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ QUESTION ANSWERING\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "question_answerer(\n",
    "    question = \"Where do i work?\",\n",
    "    context = 'My name is Saugat Regmi and I work at Mercantile Inc in Kathmandu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtW3Ff2afjUM"
   },
   "source": [
    "**7. Summarization**\n",
    "\n",
    "- Summarization helps in the task reducing a text into a shorter text while keeping all of the important aspects referenced in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0p0VjUXjaFM",
    "outputId": "58839f31-460b-49d6-c3c6-bf19139e78e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Rajesh Hamal is the son of a diplomat, a scholarly man with a master’s degree in English Literature, a Goodwill Ambassador and a recurrent contributor to charity . He has starred in a staggering number of films and television shows . His dedicated acting career has redefined the classifications of what it means to be a Nepali actor .'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ SUMMARIZATION\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "summarizer(\"\"\"\n",
    "  Rajesh Hamal: the son of a diplomat, a scholarly man with a master’s degree in English Literature, a Goodwill Ambassador and recurrent contributor to charity. But you may know him better as the ‘Great Actor’ of Nepal, starring in award winning films such as Deuta (1992), for which he won the first of many Best Actor Awards by the National Film Award, the most prestigious cinematic awards association in Nepal.\n",
    "Since his film debut in the late 1980’s and his seemingly overnight rise to stardom, he has become one of the most, if not the most, iconic figures of Nepali cinema. His roles ranged in character and variety from light hearted romantic comedy,to seat-gripping action and adventure. His cinematic success has not gone unnoticed; he’s the recipient of three decades worth of Best Actor awards and nominations, in addition to numerous other achievements. It seems as if there is nothing that Mr. Hamal cannot do.\n",
    "Rajesh Hamal has become common household name in Nepal. His dedicated acting career has redefined the classifications of what it means to be a Nepali actor. His near record-breaking number of films and acting achievements have not only inspired actors (aspiring and seasoned actors alike), but has given Nepali cinema an unparalleled level of credibility, and has changed the country’s cinematic culture towards higher standards of professionalism and quality.\n",
    "Early Life Before Acting Hamal was born on June 4, 1964 in Tansen, in the heart of Nepal. Though he has starred in a staggering number of films and television shows, his fruitfulcareer in film did not begin until his adult years, his mid-twenties, in the early 1990’s.\n",
    "He spent the majority of his childhood in hometown in Nepal, attending private school until the eighth grade.As an early teen, he accompanied his father on a cross-continental move to Moscow. At the time, his father was a political diplomat for Nepalese government. Hamal and his father remained in Russia for a number of years. Hamal even began attending college in Moscow. However, he returned to India to finish his formal education in Lahore, at the Punjab University. It was there that he graduated with a M.A. in English Literature.\n",
    "Hamal’s introduction to the camera began upon his return to India in his college years. His exposure started not in cinematic film, but rather in modelling. His infamous modelling career was relatively short-lived, lasting only for a couple years in the mid 1980’s, buthe became one of India’s most popular male models at the time.  His characteristic long black hair and striking good looks did not go unnoticed.  He appeared sporting the latest clothing fashions on runways in Kathmandu and New Delhi, and was featured in the renowned Indian fashion magazine, Fashion Net.\n",
    "While he was quite successful as a model, earning the titles of Best Ramp Performer and Model of the Year in 1989, his aspirations for something more would not be satisfied with modelling. His time in the modelling spotlight soon transformed into something much bigger. Altering not only his life, but the entertainment industry of Nepal as well.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKvrrA_KfwAx"
   },
   "source": [
    "**8. Language Translation**\n",
    "\n",
    "- This pipeline helps in translating the words or sentences from one langauge to another lanauge\n",
    "\n",
    "- We can specify `max_length` or `min_length` for the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5bQJPa7kPCj",
    "outputId": "e4a26b7d-19cf-4597-ecbb-d53711ce82d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ LANGUAGE TRANSLATION\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\", tokenizer=tokenizer)\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJZE5VllkLvY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
